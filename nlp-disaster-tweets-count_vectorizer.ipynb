{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"         id keyword location  \\\n0         1     NaN      NaN   \n1         4     NaN      NaN   \n2         5     NaN      NaN   \n3         6     NaN      NaN   \n4         7     NaN      NaN   \n...     ...     ...      ...   \n7608  10869     NaN      NaN   \n7609  10870     NaN      NaN   \n7610  10871     NaN      NaN   \n7611  10872     NaN      NaN   \n7612  10873     NaN      NaN   \n\n                                                   text  target  \n0     Our Deeds are the Reason of this #earthquake M...       1  \n1                Forest fire near La Ronge Sask. Canada       1  \n2     All residents asked to 'shelter in place' are ...       1  \n3     13,000 people receive #wildfires evacuation or...       1  \n4     Just got sent this photo from Ruby #Alaska as ...       1  \n...                                                 ...     ...  \n7608  Two giant cranes holding a bridge collapse int...       1  \n7609  @aria_ahrary @TheTawniest The out of control w...       1  \n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n7611  Police investigating after an e-bike collided ...       1  \n7612  The Latest: More Homes Razed by Northern Calif...       1  \n\n[7613 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows Ã— 5 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing tweets that are positive","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df[\"target\"] == 0][\"text\"].values[1]","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"'I love fruits'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"And one that is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df[\"target\"] == 1][\"text\"].values[1]","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"'Forest fire near La Ronge Sask. Canada'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Tokenizing the first 5 tweets using scikit learn's CountVectorizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = feature_extraction.text.CountVectorizer()\n\n## let's get counts for the first 5 tweets in the data\nexample_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\nprint(example_train_vectors[0].todense().shape)\nprint(example_train_vectors[0].todense())","execution_count":11,"outputs":[{"output_type":"stream","text":"(1, 54)\n[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The above tells us that:\n1. There are 54 unique words (or \"tokens\") in the first five tweets.\n2. The first tweet contains only some of those unique tokens - all of the non-zero counts above are the tokens that DO exist in the first tweet.\n\nNow let's create vectors for all of our tweets."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n\n## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n# that the tokens in the train vectors are the only ones mapped to the test vectors - \n# i.e. that the train and test vectors use the same set of tokens.\ntest_vectors = count_vectorizer.transform(test_df[\"text\"])","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Our model\n\nAs we mentioned above, we think the words contained in each tweet are a good indicator of whether they're about a real disaster or not. The presence of particular word (or set of words) in a tweet might link directly to whether or not that tweet is real.\n\nWhat we're assuming here is a _linear_ connection. So let's build a linear model and see!"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Our vectors are really big, so we want to push our model's weights\n## toward 0 without completely discounting different words - ridge regression \n## is a good way to do this.\nclf = linear_model.RidgeClassifier()","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's test our model and see how well it does on the training data. For this we'll use `cross-validation` - where we train on a portion of the known data, then validate it with the rest. If we do this several times (with different portions) we can get a good idea for how a particular model or method performs.\n\nThe metric for this competition is F1, so let's use that here."},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\nscores","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"array([0.60355649, 0.57580105, 0.64485082])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The above scores aren't terrible! It looks like our assumption will score roughly 0.65 on the leaderboard. There are lots of ways to potentially improve on this (TFIDF, LSA, LSTM / RNNs, the list is long!) - give any of them a shot!\n\nIn the meantime, let's do predictions on our training set and build a submission for the competition."},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(train_vectors, train_df[\"target\"])","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n                max_iter=None, normalize=False, random_state=None,\n                solver='auto', tol=0.001)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission[\"target\"] = clf.predict(test_vectors)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"   id  target\n0   0       0\n1   2       1\n2   3       1\n3   9       0\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index=False)","execution_count":19,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}